{"paragraphs":[{"text":"%md\n# About\n**Lab:** Persisting DataFrames\n**Objective:** Explore DataFrame persistence.\n**File locations:**\n    Data files (HDFS): /user/zeppelin/accountdevice\n    Hive tables: telco.accounts\n**Successful outcome:** \n**Before you begin:** \n**Related lessons:** \n\n---","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>About</h1>\n<p><strong>Lab:</strong> Persisting DataFrames\n<br  /><strong>Objective:</strong> Explore DataFrame persistence.\n<br  /><strong>File locations:</strong></p>\n<pre><code>Data files (HDFS): /devsh_loudacre/accountdevice\nHive tables: devsh.accounts\n</code></pre>\n<p><strong>Successful outcome:</strong>\n<br  /><strong>Before you begin:</strong>\n<br  /><strong>Related lessons:</strong></p>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1591815465176_-1896242454","id":"20181126-092644_1457476546","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:139959"},{"text":"%md\n# Setup","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Setup</h1>\n<p><strong>Important:</strong> This exercise depends on <strong><em> ***Insert previous exercise title here (with link?)*** </em></strong>. If you did not complete that exercise, run the course catch-up script and advance to the current exercise:</p>\n<pre><code>$ $DEVSH/scripts/catchup.sh\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1591815465177_-133937264","id":"20181201-044336_178705192","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139960"},{"text":"%md\n# Lab\n","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Lab</h1>\n"}]},"apps":[],"jobName":"paragraph_1591815465177_243881697","id":"20181126-093358_358613711","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139961"},{"text":"%md\n### Compare the Execution Plans of Persisted and Unpersisted Queries","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Compare the Execution Plans of Persisted and Unpersisted Queries</h3>\n"}]},"apps":[],"jobName":"paragraph_1591815465177_1315494489","id":"20200426-035337_1420000263","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139962"},{"title":"1 - Join accounts with their associated devices","text":"%md\nCreate a DataFrame that joins account data for all accounts with their associated devices. To save time and effort, some stub code has been provided for you.","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>??? Add this code here to run ???</h3>\n"}]},"apps":[],"jobName":"paragraph_1591815465177_-733191519","id":"20200426-035404_1322046437","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139963"},{"text":"%pyspark\n# stub: query setup\naccountsDF = spark.read.table(\"telco.accounts\")\naccountDeviceDF = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").csv(\"/user/zeppelin/accountdevice\")\naccountsDevsDF =  accountsDF.join(accountDeviceDF,accountsDF.acct_num == accountDeviceDF.account_id)","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591815465178_-480656385","id":"20200429-210012_1471698944","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139964"},{"title":"2 - Display info from the new DataFrame","text":"%md\n\nThe query code you pasted above defines a new DataFrame called `accountsDevsDF`, which joins account data and device data. Try executing a query starting with the accountsDevsDF DataFrame that displays the account number, first name, last name and device ID for each row.","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591815465178_-1000029675","id":"20200426-035403_1370280892","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139965"},{"text":"%pyspark\naccountsDevsDF. \\\nselect(\"acct_num\",\"first_name\",\"last_name\",\"device_id\"). \\\nshow(5)","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591815465178_33202873","id":"20200426-035403_1059527028","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139966"},{"title":"3 - Note the complexity of the query you just executed","text":"%md\nIn your browser, go to the **SQL** tab of your application's Spark UI, and view the execution visualization of the query you just executed. Take note of the complexity so that you can compare it to later executions when using persistence. \n\nRemember that queries are listed in the **SQL** tab in the order they were executed, starting with the most recent. The descriptions of multiple executions of the same action will not distinguish one query from another, so make sure you choose the correct one for the query you are looking at.","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591815465178_1704845056","id":"20200426-035402_1252980857","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139967"},{"title":"4 - Persist accountsDevsDF","text":"%md\nIn your Spark shell, persist the `accountsDevsDF` DataFrame using the default storage level.","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591815465179_-502760187","id":"20200426-035401_1680646515","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139968"},{"text":"%pyspark\naccountsDevsDF.persist()","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591815465179_928091883","id":"20200426-035401_1324998326","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139969"},{"title":"5 - Repeat the final steps of the query you executed above","text":"%pyspark\naccountsDevsDF. \\\nselect(\"acct_num\",\"first_name\",\"last_name\",\"device_id\"). \\\nshow(5)","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591815465179_-1865274273","id":"20200426-035400_914284045","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139970"},{"title":"6 - Compare the execution diagram of this query with the one executed before","text":"%md\nIn the browser, reload the Spark UI **SQL** tab, and view the execution diagram for the query just executed. Notice that it has far fewer steps. Instead of reading, filtering, and joining the data from the two sources, it reads the persisted data from memory. If you hover your mouse over the memory scan step, you will see that the only operation it performs on the data in memory is the last step of the query: the unpersisted select transformation. Compare the diagram for this query with the first one you executed above, before persisting.","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591815465179_1964340801","id":"20200426-035358_1654934869","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139971"},{"title":"7 - Analyze the two execution diagrams","text":"%md\nThe first time you execute a query on a persisted DataFrame, Dataset, or RDD, Spark has to execute the full query in order to materialize the data that gets saved in memory or on disk. Compare the difference between the first and second queries after executing `persist` by re-executing the query one final time. Then use the Spark UI to compare both queries executed after the `persist` operation, and consider these questions.\n\n- Do the execution diagrams differ? Why or why not?\n- Did one query take longer than the other? If so, which one, and why?","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<ul>\n<li>Do the execution diagrams differ? Why or why not?</li>\n<li>Did one query take longer than the other? If so, which one, and why?</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1591815465179_-1202052653","id":"20200426-035358_848001533","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139972"},{"text":"%md\n### View Storage for Persisted DataFrames","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>View Storage for Persisted DataFrames</h3>\n"}]},"apps":[],"jobName":"paragraph_1591815465180_1481762136","id":"20200426-035357_341037510","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139973"},{"title":"8 - Review the properties of the RDD","text":"%md\nView the **Storage** tab in the Spark UI to see currently persisted data. The list shows the RDD identified by the execution plan for the query that generated the data. Consider these questions.\n\n- What is the storage level of the RDD?\n- How many partitions of the RDD were persisted and how much space do those partitions take up in memory and on disk?\n- Note that only a small percentage of the data is cached. Why is that? How could you cache more of the data?\n- Click the RDD name to view the storage details. Which executors are storing data for this RDD?","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<ul>\n<li>What is the storage level of the RDD?</li>\n<li>How many partitions of the RDD were persisted and how much space do those\n<br  />partitions take up in memory and on disk?</li>\n<li>Note that only a small percentage of the data is cached. Why is that? How could\n<br  />you cache more of the data?</li>\n<li>Click the RDD name to view the storage details. Which executors are storing data\n<br  />for this RDD?</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1591815465180_347575075","id":"20200426-035346_198043054","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139974"},{"title":"9 - Execute the query using the write action","text":"%md\nExecute the same query as above using the write action instead of show.","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Execute the same query as above using the write action instead of show.</p>\n"}]},"apps":[],"jobName":"paragraph_1591815465180_97725979","id":"20200426-035345_2068263348","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139975"},{"text":"%pyspark\naccountsDevsDF.write.mode(\"overwrite\"). \\\nsave(\"/user/zeppelin/accounts_devices\")","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591815465180_-335722274","id":"20200426-035345_1468680125","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139976"},{"title":"10 - Analyze the storage used with the new version of the query","text":"%md\nReload the Spark UI **Storage** tab.\n\n- What percentage of the data is cached? Why? How does this compare to the last\ntime you persisted the data?\n- How much memory is the data taking up? How much disk space?","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Reload the Spark UI <strong>Storage</strong> tab.</p>\n<ul>\n<li>What percentage of the data is cached? Why? How does this compare to the last\n<br  />time you persisted the data?</li>\n<li>How much memory is the data taking up? How much disk space?</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1591815465181_-1620985963","id":"20200426-062545_1647187544","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139977"},{"text":"%md\n### Change the Storage Level for the Persisted DataFrame","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Change the Storage Level for the Persisted DataFrame</h3>\n"}]},"apps":[],"jobName":"paragraph_1591815465181_1450221387","id":"20200426-062544_2035581418","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139978"},{"title":"11 - Unpersist the accountsDevsDF DataFrame","text":"%pyspark\naccountsDevsDF.unpersist()","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591815465181_1831840244","id":"20200426-062544_2125101715","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139979"},{"title":"12 - Verify that the cache has been removed","text":"%md\nView the Spark UI **Storage** to verify that the cache for `accountsDevsDF` has been removed.","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591815465181_1864933084","id":"20200426-062543_1322148377","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139980"},{"title":"13 - Persist the same DataFrame again","text":"%md\nRepersist the same DataFrame, setting the storage level to save the data files on disk, replicated twice.","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591815465181_1838628622","id":"20200426-062542_123835292","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139981"},{"text":"%pyspark\nfrom pyspark import StorageLevel\n\naccountsDevsDF.persist(StorageLevel.DISK_ONLY_2)","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591815465182_-641925365","id":"20200426-062542_1989337635","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139982"},{"title":"14 - Re-execute the previous query","text":"%pyspark\n","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591815465182_-589965827","id":"20200426-062541_564847369","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139983"},{"title":"15 - Analyze how the data is stored","text":"%md\nReload the **Storage** tab to confirm that the storage level for the RDD is set correctly.\nAlso consider these questions:\n\n- How much memory is the data taking up? How much disk space?\n- Which executors are storing the RDD's data files?\n- How many partitions are stored? Are they replicated? Where?","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Reload the <strong>Storage</strong> tab to confirm that the storage level for the RDD is set correctly.\n<br  />Also consider these questions:</p>\n<ul>\n<li>How much memory is the data taking up? How much disk space?</li>\n<li>Which executors are storing the RDD's data files?</li>\n<li>How many partitions are stored? Are they replicated? Where?</li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1591815465182_-895573397","id":"20200426-062541_214949809","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139984"},{"text":"%md\n# Result\n**You have now:** \n\n---","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Result</h1>\n<p><strong>You have now:</strong></p>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1591815465182_30567398","id":"20181126-133507_1472573213","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139985"},{"text":"%md\n# Solution\n---","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Solution</h1>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1591815465182_-1821541822","id":"20181018-125200_1133281582","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139986"},{"text":"%md\n### Compare the Execution Plans of Persisted and Unpersisted Queries","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591815465183_371216508","id":"20200429-205813_408772061","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139987"},{"title":"1 - Join accounts with their associated devices","text":"%pyspark\n# stub: query setup\naccountsDF = spark.read.table(\"telco.accounts\")\naccountDeviceDF = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").csv(\"/user/zeppelin/accountdevice\")\naccountsDevsDF =  accountsDF.join(accountDeviceDF,accountsDF.acct_num == accountDeviceDF.account_id)","user":"sysadmin","dateUpdated":"2020-06-10T19:38:31+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1591815465183_1239168155","id":"20200429-205812_1635150681","dateCreated":"2020-06-10T18:57:45+0000","dateStarted":"2020-06-10T19:38:31+0000","dateFinished":"2020-06-10T19:38:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:139988"},{"title":"2 - Display info from the new DataFrame","text":"%pyspark\naccountsDevsDF.select(\"acct_num\",\"first_name\",\"last_name\",\"device_id\").show(5)","user":"sysadmin","dateUpdated":"2020-06-10T19:38:33+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------+----------+---------+---------+\n|acct_num|first_name|last_name|device_id|\n+--------+----------+---------+---------+\n|       1|    Donald|   Becton|       29|\n|       1|    Donald|   Becton|        9|\n|       2|     Donna|    Jones|        5|\n|       3|    Dorthy| Chalmers|        5|\n|       4|     Leila|  Spencer|       38|\n+--------+----------+---------+---------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1591815465183_-1920768719","id":"20200429-205855_48052881","dateCreated":"2020-06-10T18:57:45+0000","dateStarted":"2020-06-10T19:38:33+0000","dateFinished":"2020-06-10T19:38:34+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:139989"},{"title":"3 - Note the complexity of the query you just executed","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591815465183_-699024431","id":"20200429-205854_1575015129","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139990"},{"title":"4 - Persist accountsDevsDF","text":"%pyspark\naccountsDevsDF.persist()","user":"sysadmin","dateUpdated":"2020-06-10T19:38:39+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"DataFrame[acct_num: int, acct_create_dt: timestamp, acct_close_dt: timestamp, first_name: string, last_name: string, address: string, city: string, state: string, zipcode: string, phone_number: string, created: timestamp, modified: timestamp, id: int, account_id: int, device_id: int, activation_date: bigint, account_device_id: string]\n"}]},"apps":[],"jobName":"paragraph_1591815465184_819038076","id":"20200429-205854_261598927","dateCreated":"2020-06-10T18:57:45+0000","dateStarted":"2020-06-10T19:38:39+0000","dateFinished":"2020-06-10T19:38:40+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:139991"},{"title":"5 - Repeat the final steps of the query you executed above","text":"%pyspark\naccountsDevsDF.select(\"acct_num\",\"first_name\",\"last_name\",\"device_id\").show(5)","user":"sysadmin","dateUpdated":"2020-06-10T19:38:42+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------+----------+---------+---------+\n|acct_num|first_name|last_name|device_id|\n+--------+----------+---------+---------+\n|       1|    Donald|   Becton|       29|\n|       1|    Donald|   Becton|        9|\n|       2|     Donna|    Jones|        5|\n|       3|    Dorthy| Chalmers|        5|\n|       4|     Leila|  Spencer|       38|\n+--------+----------+---------+---------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1591815465184_-1659553137","id":"20200429-205852_1436750479","dateCreated":"2020-06-10T18:57:45+0000","dateStarted":"2020-06-10T19:38:42+0000","dateFinished":"2020-06-10T19:38:43+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:139992"},{"title":"6 - Compare the execution diagram of this query with the one executed before","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591815465184_1676526311","id":"20200429-205851_2101455775","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139993"},{"title":"7 - Analyze the two execution diagrams","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591815465184_1275475994","id":"20200429-205850_795239181","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139994"},{"text":"%md\n### View Storage for Persisted DataFrames","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591815465184_451441392","id":"20200429-205850_1346508345","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139995"},{"title":"8 - Review the properties of the RDD","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591815465185_-741224559","id":"20200429-205849_384433336","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139996"},{"title":"9 - Execute the query using the write action","text":"%pyspark\naccountsDevsDF.write.mode(\"overwrite\").save(\"/user/zeppelin/accounts_devices\")","user":"sysadmin","dateUpdated":"2020-06-10T19:38:48+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1591815465185_968512099","id":"20200429-205849_124172407","dateCreated":"2020-06-10T18:57:45+0000","dateStarted":"2020-06-10T19:38:48+0000","dateFinished":"2020-06-10T19:38:52+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:139997"},{"title":"10 - Analyze the storage used with the new version of the query","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591815465185_189984994","id":"20200429-205848_1867896831","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139998"},{"text":"%md\n### Change the Storage Level for the Persisted DataFrame","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591815465185_-671991700","id":"20200429-205847_1965596134","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:139999"},{"title":"11 - Unpersist the accountsDevsDF DataFrame","text":"%pyspark\naccountsDevsDF.unpersist()","user":"sysadmin","dateUpdated":"2020-06-10T19:38:57+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"DataFrame[acct_num: int, acct_create_dt: timestamp, acct_close_dt: timestamp, first_name: string, last_name: string, address: string, city: string, state: string, zipcode: string, phone_number: string, created: timestamp, modified: timestamp, id: int, account_id: int, device_id: int, activation_date: bigint, account_device_id: string]\n"}]},"apps":[],"jobName":"paragraph_1591815465186_738112912","id":"20200429-205847_1443153254","dateCreated":"2020-06-10T18:57:45+0000","dateStarted":"2020-06-10T19:38:57+0000","dateFinished":"2020-06-10T19:38:57+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:140000"},{"title":"12 - Verify that the cache has been removed","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591815465186_-1508992156","id":"20200429-205845_471575397","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140001"},{"title":"13 - Persist the same DataFrame again","text":"%pyspark\nfrom pyspark import StorageLevel  \naccountsDevsDF.persist(StorageLevel.DISK_ONLY_2)","user":"sysadmin","dateUpdated":"2020-06-10T19:39:00+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"DataFrame[acct_num: int, acct_create_dt: timestamp, acct_close_dt: timestamp, first_name: string, last_name: string, address: string, city: string, state: string, zipcode: string, phone_number: string, created: timestamp, modified: timestamp, id: int, account_id: int, device_id: int, activation_date: bigint, account_device_id: string]\n"}]},"apps":[],"jobName":"paragraph_1591815465186_160079461","id":"20200429-205845_961146902","dateCreated":"2020-06-10T18:57:45+0000","dateStarted":"2020-06-10T19:39:00+0000","dateFinished":"2020-06-10T19:39:00+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:140002"},{"title":"14 - Re-execute the previous query","text":"%pyspark\naccountsDevsDF.write.mode(\"overwrite\").save(\"/user/zeppelin/accounts_devices\")","user":"sysadmin","dateUpdated":"2020-06-10T19:39:05+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1591815465186_7484016","id":"20200429-205844_451916861","dateCreated":"2020-06-10T18:57:45+0000","dateStarted":"2020-06-10T19:39:05+0000","dateFinished":"2020-06-10T19:39:09+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:140003"},{"title":"15 - Analyze how the data is stored","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591815465186_404795455","id":"20200429-205842_2001073669","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140004"},{"text":"%md\nWe hope you've enjoyed this lab. Below are additional resources that you should find useful:\n\n1. [Hortonworks Apache Spark Tutorials](http://hortonworks.com/tutorials/#tuts-developers) are your natural next step where you can explore Spark in more depth.\n2. [Hortonworks Community Connection (HCC)](https://community.hortonworks.com/spaces/85/data-science.html?type=question) is a great resource for questions and answers on Spark, Data Analytics/Science, and many more Big Data topics.\n3. [Hortonworks Apache Spark Docs](https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.1/spark-overview/content/analyzing_data_with_apache_spark.html) - official Spark documentation.\n4. [Hortonworks Apache Zeppelin Docs](https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.1/zeppelin-overview/content/overview.html) - official Zeppelin documentation.\n","user":"sysadmin","dateUpdated":"2020-06-10T18:57:45+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>We hope you've enjoyed this lab. Below are additional resources that you should find useful:</p>\n<ol>\n<li><a href=\"http://hortonworks.com/tutorials/#tuts-developers\">Hortonworks Apache Spark Tutorials</a> are your natural next step where you can explore Spark in more depth.</li>\n<li><a href=\"https://community.hortonworks.com/spaces/85/data-science.html?type=question\">Hortonworks Community Connection (HCC)</a> is a great resource for questions and answers on Spark, Data Analytics/Science, and many more Big Data topics.</li>\n<li><a href=\"https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.1/spark-overview/content/analyzing_data_with_apache_spark.html\">Hortonworks Apache Spark Docs</a> - official Spark documentation.</li>\n<li><a href=\"https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.1/zeppelin-overview/content/overview.html\">Hortonworks Apache Zeppelin Docs</a> - official Zeppelin documentation.</li>\n</ol>\n"}]},"apps":[],"jobName":"paragraph_1591815465187_2041167304","id":"20181126-133017_244739700","dateCreated":"2020-06-10T18:57:45+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:140005"}],"name":"PYSPARK/14-PersistingDataFrames","id":"2FBAECHRN","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"sh:shared_process":[],"jdbc:shared_process":[],"spark2:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}