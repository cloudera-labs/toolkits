{"paragraphs":[{"text":"%md\n# About\n**Lab:** Working with RDDs\n**Objective:** Use the Spark shell to work with RDDs\n**File locations:**\n    /home/devuser/data/telco/frostroad.txt\n    /home/devuser/data/telco/makes1.txt\n    /home/devuser/data/telco/makes2.txt\n    \n**Successful outcome:** \n**Before you begin:** \n**Related lessons:** \n\n---","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>About</h1>\n<p><strong>Lab:</strong> Working with RDDs\n<br  /><strong>Objective:</strong> Use the Spark shell to work with RDDs\n<br  /><strong>File locations:</strong></p>\n<pre><code>$DEVDATA/frostroad.txt\n$DEVDATA/makes1.txt\n$DEVDATA/makes2.txt\n</code></pre>\n<p><strong>Successful outcome:</strong>\n<br  /><strong>Before you begin:</strong>\n<br  /><strong>Related lessons:</strong></p>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1591819974609_-1349863874","id":"20181126-092644_1457476546","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:814"},{"text":"%md\n# Setup","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Setup</h1>\n<p><strong>Important:</strong> This exercise depends on <strong><em> ***Insert previous exercise title here (with link?)*** </em></strong>. If you did not complete that exercise, run the course catch-up script and advance to the current exercise:</p>\n<pre><code>$ $DEVSH/scripts/catchup.sh\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1591819974609_893991630","id":"20181201-044336_178705192","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:815"},{"text":"%md\n# Lab\n","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Lab</h1>\n"}]},"apps":[],"jobName":"paragraph_1591819974610_81950444","id":"20181126-093358_358613711","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:816"},{"text":"%md\n### Review the API Documentation for RDD Operations","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Review the API Documentation for RDD Operations</h3>\n"}]},"apps":[],"jobName":"paragraph_1591819974610_216558153","id":"20200428-024704_138128985","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:817"},{"title":"1 - Review the API documentation for the RDD class","text":"%md\nReview the API docs for the RDD class (which is in the Python module `pyspark`). Take note of the various available operations.","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Review the API docs for the RDD class (which is in the Python module <code>pyspark</code>,\n<br  />and the Scala package <code>org.apache.spark.rdd</code>). Take note of the various\n<br  />available operations.</p>\n"}]},"apps":[],"jobName":"paragraph_1591819974611_-658807266","id":"20200424-215005_344934858","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:818"},{"text":"%md\n### Read and Display Data from a Text File","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Read and Display Data from a Text File</h3>\n"}]},"apps":[],"jobName":"paragraph_1591819974611_589928438","id":"20200428-024754_460071641","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:819"},{"title":"2 - Review the text file that will be the source of data","text":"%md\nReview the simple text file you will be using by viewing (without editing) the file in a separate window (not the Spark shell). The file is located at `/home/devuser/data/telco/frostroad.txt`.","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Review the simple text file you will be using by viewing (without editing) the\n<br  />file in a separate window (not the Spark shell). The file is located at <code>$DEVDATA/frostroad.txt</code>.</p>\n"}]},"apps":[],"jobName":"paragraph_1591819974612_-1355894906","id":"20200424-214914_1115106859","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:820"},{"title":"3 - Upload the text file to HDFS","text":"%md\nIn a terminal window on your remote desktop, upload the text file to HDFS directory `/user/zeppelin/`.","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>In a terminal window on your remote desktop, upload the text file to HDFS\n<br  />directory <code>/devsh_loudacre</code>.</p>\n<pre><code>$ hdfs dfs -put $DEVDATA/frostroad.txt /devsh_loudacre/\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1591819974612_-47879159","id":"20200424-214848_506181608","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:821"},{"text":"%sh\nhdfs dfs -put /home/devuser/data/telco/frostroad.txt /user/zeppelin/","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591819974612_-926084827","id":"20200430-004323_453225455","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:822"},{"title":"4 - Define an RDD based on the source data","text":"%md\nIn the Spark shell, define an RDD based on the `frostroad.txt` text file.","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>In the Spark shell, define an RDD based on the <code>frostroad.txt</code> text file.</p>\n"}]},"apps":[],"jobName":"paragraph_1591819974613_-28082709","id":"20200424-214800_39914779","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:823"},{"text":"%spark2\nval myRDD = sc.textFile(\"/user/zeppelin/frostroad.txt\")","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591819974613_-1222059468","id":"20200424-214739_545546872","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:824"},{"title":"5 - Review the available transformations and actions for an RDD","text":"%md\nUsing command completion, you can see all the available transformations and actions you can perform on an RDD. Type `myRDD.` and then the `TAB` key.","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Using command completion, you can see all the available transformations and\n<br  />actions you can perform on an RDD. Type <code>myRDD.</code> and then the <code>TAB</code> key.</p>\n"}]},"apps":[],"jobName":"paragraph_1591819974613_731566933","id":"20200424-214640_185360290","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:825"},{"text":"%spark2\n//myRDD.","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591819974614_-1084137432","id":"20200521-205807_1239235767","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:826"},{"title":"6 - Perform an action on the RDD to materialize it in Spark","text":"%md\nSpark has not yet read the file. It will not do so until you perform an action on the RDD. Try counting the number of elements in the RDD using the `count` action:","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Spark has not yet read the file. It will not do so until you perform an action on the\n<br  />RDD. Try counting the number of elements in the RDD using the <code>count</code> action:</p>\n"}]},"apps":[],"jobName":"paragraph_1591819974614_1909625644","id":"20200424-214558_92091425","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:827"},{"text":"%spark2\nmyRDD.count","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591819974615_-1029370197","id":"20200424-214551_532106273","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:828"},{"text":"%md\nThe `count` operation causes the RDD to be materialized (created and populated).\nThe number of lines (23) should be returned.","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>The <code>count</code> operation causes the RDD to be materialized (created and populated).\n<br  />The number of lines (23) should be displayed, for example:</p>\n<pre><code>    Out[2]: 23\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1591819974615_-1265510906","id":"20200424-214418_297074465","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:829"},{"title":"7 - Use the collect operation to return all data","text":"%md\nCall the `collect` operation to return all data in the RDD to the Spark driver. Take note of the type of the return value; it will be a list of strings.\n\n**Note:** `collect` returns the entire set of data. This is convenient for very small RDDs like this one, but be careful using `collect` for more typical large sets of data.","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Call the <code>collect</code> operation to return all data in the RDD to the Spark driver. Take\n<br  />note of the type of the return value; in Python will be a list of strings, and in Scala it\n<br  />will be an array of strings.</p>\n<p><strong>Note:</strong> <code>collect</code> returns the entire set of data. This is convenient for very small\n<br  />RDDs like this one, but be careful using <code>collect</code> for more typical large sets of data.</p>\n"}]},"apps":[],"jobName":"paragraph_1591819974615_1637401573","id":"20200424-214315_1375268715","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:830"},{"text":"%spark2\nval lines = myRDD.collect","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591819974616_-1922661370","id":"20200424-214247_217269373","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:831"},{"title":"8 - Display the collected data","text":"%md\nDisplay the contents of the collected data by looping through the collection.","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Display the contents of the collected data by looping through the collection.</p>\n"}]},"apps":[],"jobName":"paragraph_1591819974616_2115541311","id":"20200424-214211_1186663796","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:832"},{"text":"%spark2\nfor (line <- lines) println(line)","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591819974616_-1599653561","id":"20200424-214159_796822712","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:833"},{"text":"%md\n### Transform Data in an RDD","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Transform Data in an RDD</h3>\n"}]},"apps":[],"jobName":"paragraph_1591819974617_-341067490","id":"20200428-025615_1070138297","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:834"},{"title":"9 - Review the data files you will be using in this exercise","text":"%md\nIn this exercise, you will load two text files containing the names of various cell phone makes, and append one to the other. Review the two text files you will be using by viewing (without editing) the file in a separate window. The files are `makes1.txt` and `makes2.txt` in the `/home/devuser/data/telco/` directory.","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>In this exercise, you will load two text files containing the names of various cell\n<br  />phone makes, and append one to the other. Review the two text files you will be\n<br  />using by viewing (without editing) the file in a separate window. The files are\n<br  /><code>makes1.txt</code> and <code>makes2.txt</code> in the <code>$DEVDATA</code> directory.</p>\n"}]},"apps":[],"jobName":"paragraph_1591819974621_2107508193","id":"20200424-214041_761824727","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:835"},{"title":"10 - Upload the data files to HDFS","text":"%md\nUpload the two text files to HDFS directory `/user/zeppelin/`.","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Upload the two text files to HDFS directory <code>/devsh_loudacre</code>.</p>\n<pre><code>$ hdfs dfs -put $DEVDATA/makes*.txt /devsh_loudacre/\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1591819974622_-75648439","id":"20200424-213909_837903176","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:836"},{"text":"%sh\nhdfs dfs -put /home/devuser/data/telco/makes*.txt /user/zeppelin/","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591819974622_-1995962153","id":"20200430-004408_331719139","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:837"},{"title":"11 - Create an RDD based on makes1.txt","text":"%md\nIn Spark, create an RDD called `makes1RDD` based on the `/user/zeppelin/makes1.txt` file.","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>In Spark, create an RDD called <code>makes1RDD</code> based on the <code>/devsh_loudacre/makes1.txt</code> file.</p>\n"}]},"apps":[],"jobName":"paragraph_1591819974622_525960463","id":"20200424-213751_536056781","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:838"},{"text":"%spark2\nval makes1RDD = sc.textFile(\"/user/zeppelin/makes1.txt\")","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591819974623_-1274440776","id":"20200424-213725_1208354403","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:839"},{"title":"12 - Display the contents from makes1 using collect","text":"%md\nDisplay the contents of the `makes1RDD` data using `collect` and then looping through the returned colleciton.","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Display the contents of the <code>makes1RDD</code> data using <code>collect</code> and then looping through the returned colleciton.</p>\n"}]},"apps":[],"jobName":"paragraph_1591819974623_281229183","id":"20200424-213513_702708207","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:840"},{"text":"%spark2\nfor (make <- makes1RDD.collect()) println(make)","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591819974623_-1604131599","id":"20200424-213434_596633543","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:841"},{"title":"13 - Create and display an RDD based on makes2.txt","text":"%md\nRepeat the previous steps to create and display an RDD called `makes2RDD` based on the second file, `/user/zeppelin/makes2.txt`.","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Repeat the previous steps to create and display an RDD called <code>makes2RDD</code> based\n<br  />on the second file, <code>/devsh_loudacre/makes2.txt</code>.</p>\n"}]},"apps":[],"jobName":"paragraph_1591819974624_1904538154","id":"20200424-213238_880056803","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:842"},{"text":"%spark2\n","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591819974624_-1887771317","id":"20200424-213417_106697386","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:843"},{"title":"14 - Create a new RDD using the union transformation","text":"%md\nCreate a new RDD by appending the second RDD to the first using the `union` transformation.","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Create a new RDD by appending the second RDD to the first using the <code>union</code> transformation.</p>\n"}]},"apps":[],"jobName":"paragraph_1591819974625_620008330","id":"20200424-213149_1585292245","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:844"},{"text":"%spark2\nval allMakesRDD = makes1RDD.union(makes2RDD)","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591819974625_-286430506","id":"20200424-213128_2053041546","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:845"},{"title":"15 - Collect and display the combined RDD","text":"%md\nCollect and display the contents of the new `allMakesRDD` RDD.","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Collect and display the contents of the new <code>allMakesRDD</code> RDD.</p>\n"}]},"apps":[],"jobName":"paragraph_1591819974625_-1905946468","id":"20200424-213043_1098211128","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:846"},{"text":"%spark2\n","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591819974626_1827239049","id":"20200424-213354_1592055627","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:847"},{"title":"16 - Remove duplicates from the combined RDD","text":"%md\nUse the `distinct` transformation to remove duplicates from `allMakesRDD`. Collect and display the contents to confirm that duplicate elements were removed.","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Use the <code>distinct</code> transformation to remove duplicates from <code>allMakesRDD</code>.\n<br  />Collect and display the contents to confirm that duplicate elements were removed.</p>\n"}]},"apps":[],"jobName":"paragraph_1591819974626_-1962149943","id":"20200424-213021_1354129143","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:848"},{"text":"%spark2\n","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591819974626_770678992","id":"20200424-213337_1881813529","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:849"},{"title":"17 - Experiment with other transformations from the RDD API","text":"%md\n*Optional:* Try performing different transformations on the RDDs you created above, such as `intersection`, `subtract`, or `zip`. See the RDD API documentation for details.","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p><em>Optional:</em> Try performing different transformations on the RDDs you created above,\n<br  />such as <code>intersection</code>, <code>subtract</code>, or <code>zip</code>. See the RDD API documentation for\n<br  />details.</p>\n"}]},"apps":[],"jobName":"paragraph_1591819974627_-555088216","id":"20200424-212935_906521809","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:850"},{"text":"%spark2\n","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591819974627_686548708","id":"20200428-030537_598669703","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:851"},{"text":"%md\n# Result\n**You have now:** \n\n---","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Result</h1>\n<p><strong>You have now:</strong></p>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1591819974628_2131630222","id":"20181126-133507_1472573213","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:852"},{"text":"%md\n# Solution\n---","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>Solution</h1>\n<hr />\n"}]},"apps":[],"jobName":"paragraph_1591819974628_101333528","id":"20181018-125200_1133281582","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:853"},{"text":"%md\n### Review the API Documentation for RDD Operations","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591819974628_-1321049852","id":"20200429-021501_1550821446","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:854"},{"title":"1 - Review the API documentation for the RDD","text":"","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591819974629_-1883620696","id":"20200429-021541_2077536231","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:855"},{"text":"%md\n### Read and Display Data from a Text File","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591819974629_636420409","id":"20200429-021519_1734766452","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:856"},{"title":"2 - Review the text file that will be the source of data","text":"","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591819974629_-1965225779","id":"20200429-021611_378666460","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:857"},{"title":"3 - Upload the text file to HDFS","text":"%sh\nhdfs dfs -put /home/devuser/data/telco/frostroad.txt /user/zeppelin/","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1591819974630_1755070573","id":"20200429-021641_1994322665","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:858"},{"title":"4 - Define an RDD based on the source data","text":"%spark2\nval myRDD = sc.textFile(\"/user/zeppelin/frostroad.txt\")","user":"sysadmin","dateUpdated":"2020-06-10T23:06:34+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"myRDD: org.apache.spark.rdd.RDD[String] = /user/zeppelin/frostroad.txt MapPartitionsRDD[771] at textFile at <console>:28\n"}]},"apps":[],"jobName":"paragraph_1591819974630_47026801","id":"20200429-021639_1441334608","dateCreated":"2020-06-10T20:12:54+0000","dateStarted":"2020-06-10T23:06:34+0000","dateFinished":"2020-06-10T23:06:34+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:859"},{"title":"5 - Review the available transformations and actions for an RDD","text":"%spark2\n//myRDD.","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Instructions: Using <strong>command completionn</strong>, you can see all the available transformations and actions you can perform on an RDD. Type <code>myRDD.</code> and then the <code>TAB</code> key.</p>\n<p><strong><em> !!! Does this step need paragraphs for code? !!! </em></strong></p>\n"}]},"apps":[],"jobName":"paragraph_1591819974630_1187215890","id":"20200429-021638_1798943343","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:860"},{"title":"6 - Perform an action on the RDD to materialize it in Spark","text":"%spark2\nmyRDD.count","user":"sysadmin","dateUpdated":"2020-06-10T23:06:40+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res32: Long = 23\n"}]},"apps":[],"jobName":"paragraph_1591819974631_146825945","id":"20200429-021637_427520028","dateCreated":"2020-06-10T20:12:54+0000","dateStarted":"2020-06-10T23:06:40+0000","dateFinished":"2020-06-10T23:06:40+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:861"},{"title":"7 - Use the collect operation to return all data","text":"%spark2\nval lines = myRDD.collect","user":"sysadmin","dateUpdated":"2020-06-10T23:06:55+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"lines: Array[String] = Array(Two roads diverged in a yellow wood,, And sorry I could not travel both, And be one traveler, long I stood, And looked down one as far as I could, To where it bent in the undergrowth;, \"\", Then took the other, as just as fair,, And having perhaps the better claim,, Because it was grassy and wanted wear;, Though as for that the passing there, Had worn them really about the same,, \"\", And both that morning equally lay, In leaves no step had trodden black., Oh, I kept the first for another day!, Yet knowing how way leads on to way,, I doubted if I should ever come back., \"\", I shall be telling this with a sigh, Somewhere ages and ages hence:, Two roads diverged in a wood, and I--, I took the one less traveled by,, And that has made all the difference.)\n"}]},"apps":[],"jobName":"paragraph_1591819974631_116136200","id":"20200429-021636_1291150852","dateCreated":"2020-06-10T20:12:54+0000","dateStarted":"2020-06-10T23:06:55+0000","dateFinished":"2020-06-10T23:06:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:862"},{"title":"8 - Display the collected data","text":"%spark2\nfor(line <- lines) println(line)","user":"sysadmin","dateUpdated":"2020-06-10T23:07:04+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Two roads diverged in a yellow wood,\nAnd sorry I could not travel both\nAnd be one traveler, long I stood\nAnd looked down one as far as I could\nTo where it bent in the undergrowth;\n\nThen took the other, as just as fair,\nAnd having perhaps the better claim,\nBecause it was grassy and wanted wear;\nThough as for that the passing there\nHad worn them really about the same,\n\nAnd both that morning equally lay\nIn leaves no step had trodden black.\nOh, I kept the first for another day!\nYet knowing how way leads on to way,\nI doubted if I should ever come back.\n\nI shall be telling this with a sigh\nSomewhere ages and ages hence:\nTwo roads diverged in a wood, and I--\nI took the one less traveled by,\nAnd that has made all the difference.\n"}]},"apps":[],"jobName":"paragraph_1591819974632_313145543","id":"20200429-021634_388045641","dateCreated":"2020-06-10T20:12:54+0000","dateStarted":"2020-06-10T23:07:04+0000","dateFinished":"2020-06-10T23:07:04+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:863"},{"text":"%md\n### Transform Data in an RDD","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Transform Data in an RDD</h3>\n"}]},"apps":[],"jobName":"paragraph_1591819974632_1832348103","id":"20200429-021632_1012316340","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:864"},{"title":"9 - Review the data files you will be using in this exercise","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1591819974632_-2103148536","id":"20200429-021628_1149356867","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:865"},{"title":"10 - Upload the data files to HDFS","text":"%sh\nhdfs dfs -put /home/devuser/data/telco/makes*.txt /user/zeppelin/","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1591819974633_1268150709","id":"20200429-021625_1912713830","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:866"},{"title":"11 - Create an RDD based on makes1.txt","text":"%spark2\nval makes1RDD = sc.textFile(\"/user/zeppelin/makes1.txt\")","user":"sysadmin","dateUpdated":"2020-06-10T23:07:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"makes1RDD: org.apache.spark.rdd.RDD[String] = /user/zeppelin/makes1.txt MapPartitionsRDD[773] at textFile at <console>:28\n"}]},"apps":[],"jobName":"paragraph_1591819974633_-12380197","id":"20200429-022546_1886211172","dateCreated":"2020-06-10T20:12:54+0000","dateStarted":"2020-06-10T23:07:15+0000","dateFinished":"2020-06-10T23:07:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:867"},{"title":"12 - Display the contents from makes1 using collect","text":"%spark2\nfor (make <- makes1RDD.collect()) println(make)","user":"sysadmin","dateUpdated":"2020-06-10T23:07:20+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Sorrento\nTitanic\nSorrento\nTitanic\nMeeToo\nMeeToo\nMeeToo\nTitanic\nMeeToo\nMeeToo\nTitanic\nSorrento\nSorrento\n"}]},"apps":[],"jobName":"paragraph_1591819974633_-1850417434","id":"20200429-022541_587763068","dateCreated":"2020-06-10T20:12:54+0000","dateStarted":"2020-06-10T23:07:20+0000","dateFinished":"2020-06-10T23:07:21+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:868"},{"title":"13 - Create and display an RDD based on makes2.txt","text":"%spark2\nval makes2RDD = sc.textFile(\"/user/zeppelin/makes2.txt\")\nfor (make <- makes2RDD.collect()) println(make)","user":"sysadmin","dateUpdated":"2020-06-10T23:07:24+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Titanic\nMeeToo\nMeeToo\niFruit\niFruit\nTitanic\nMeeToo\niFruit\nTitanic\nRonin\nTitanic\nTitanic\nTitanic\nmakes2RDD: org.apache.spark.rdd.RDD[String] = /user/zeppelin/makes2.txt MapPartitionsRDD[775] at textFile at <console>:28\n"}]},"apps":[],"jobName":"paragraph_1591819974634_486766670","id":"20200429-022541_477617806","dateCreated":"2020-06-10T20:12:54+0000","dateStarted":"2020-06-10T23:07:24+0000","dateFinished":"2020-06-10T23:07:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:869"},{"title":"14 - Create a new RDD using the union transformation","text":"%spark2\nval allMakesRDD = makes1RDD.union(makes2RDD)","user":"sysadmin","dateUpdated":"2020-06-10T23:07:30+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"allMakesRDD: org.apache.spark.rdd.RDD[String] = UnionRDD[776] at union at <console>:30\n"}]},"apps":[],"jobName":"paragraph_1591819974634_1864368453","id":"20200429-022539_1667616499","dateCreated":"2020-06-10T20:12:54+0000","dateStarted":"2020-06-10T23:07:30+0000","dateFinished":"2020-06-10T23:07:30+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:870"},{"title":"15 - Collect and display the combined RDD","text":"%spark2\nfor (make <- allMakesRDD.collect()) println(make)","user":"sysadmin","dateUpdated":"2020-06-10T23:07:32+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Sorrento\nTitanic\nSorrento\nTitanic\nMeeToo\nMeeToo\nMeeToo\nTitanic\nMeeToo\nMeeToo\nTitanic\nSorrento\nSorrento\nTitanic\nMeeToo\nMeeToo\niFruit\niFruit\nTitanic\nMeeToo\niFruit\nTitanic\nRonin\nTitanic\nTitanic\nTitanic\n"}]},"apps":[],"jobName":"paragraph_1591819974635_-1660867623","id":"20200429-022537_1327595418","dateCreated":"2020-06-10T20:12:54+0000","dateStarted":"2020-06-10T23:07:32+0000","dateFinished":"2020-06-10T23:07:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:871"},{"title":"16 - Remove duplicates from the combined RDD","text":"%spark2\nval distinctMakesRDD = allMakesRDD.distinct\nfor (make <- distinctMakesRDD.collect()) println(make)","user":"sysadmin","dateUpdated":"2020-06-10T23:07:53+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Sorrento\nTitanic\nRonin\nMeeToo\niFruit\ndistinctMakesRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[779] at distinct at <console>:28\n"}]},"apps":[],"jobName":"paragraph_1591819974635_1137251878","id":"20200429-022536_125850336","dateCreated":"2020-06-10T20:12:54+0000","dateStarted":"2020-06-10T23:07:53+0000","dateFinished":"2020-06-10T23:07:54+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:872"},{"title":"17 - Experiment with other transformations from the RDD API","text":"%spark2\nprintln(\"Zip:\")\nmakes2RDD.zip(makes1RDD).collect.foreach(println)\n\nprintln(\"\\nIntersection:\")\nmakes2RDD.intersection(makes1RDD).collect.foreach(println)\n\nprintln(\"\\nSubtract\")\nmakes2RDD.subtract(makes1RDD).collect.foreach(println)","user":"sysadmin","dateUpdated":"2020-06-10T23:09:03+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Zip:\n(Titanic,Sorrento)\n(MeeToo,Titanic)\n(MeeToo,Sorrento)\n(iFruit,Titanic)\n(iFruit,MeeToo)\n(Titanic,MeeToo)\n(MeeToo,MeeToo)\n(iFruit,Titanic)\n(Titanic,MeeToo)\n(Ronin,MeeToo)\n(Titanic,Titanic)\n(Titanic,Sorrento)\n(Titanic,Sorrento)\n\nIntersection:\nTitanic\nMeeToo\n\nSubtract\nRonin\niFruit\niFruit\niFruit\n"}]},"apps":[],"jobName":"paragraph_1591819974635_-1073086752","id":"20200429-022534_1666340933","dateCreated":"2020-06-10T20:12:54+0000","dateStarted":"2020-06-10T23:09:03+0000","dateFinished":"2020-06-10T23:09:04+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:873"},{"text":"%md\nWe hope you've enjoyed this lab. Below are additional resources that you should find useful:\n\n1. [Hortonworks Apache Spark Tutorials](http://hortonworks.com/tutorials/#tuts-developers) are your natural next step where you can explore Spark in more depth.\n2. [Hortonworks Community Connection (HCC)](https://community.hortonworks.com/spaces/85/data-science.html?type=question) is a great resource for questions and answers on Spark, Data Analytics/Science, and many more Big Data topics.\n3. [Hortonworks Apache Spark Docs](https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.1/spark-overview/content/analyzing_data_with_apache_spark.html) - official Spark documentation.\n4. [Hortonworks Apache Zeppelin Docs](https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.1/zeppelin-overview/content/overview.html) - official Zeppelin documentation.\n","user":"sysadmin","dateUpdated":"2020-06-10T20:12:54+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>We hope you've enjoyed this lab. Below are additional resources that you should find useful:</p>\n<ol>\n<li><a href=\"http://hortonworks.com/tutorials/#tuts-developers\">Hortonworks Apache Spark Tutorials</a> are your natural next step where you can explore Spark in more depth.</li>\n<li><a href=\"https://community.hortonworks.com/spaces/85/data-science.html?type=question\">Hortonworks Community Connection (HCC)</a> is a great resource for questions and answers on Spark, Data Analytics/Science, and many more Big Data topics.</li>\n<li><a href=\"https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.1/spark-overview/content/analyzing_data_with_apache_spark.html\">Hortonworks Apache Spark Docs</a> - official Spark documentation.</li>\n<li><a href=\"https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.1/zeppelin-overview/content/overview.html\">Hortonworks Apache Zeppelin Docs</a> - official Zeppelin documentation.</li>\n</ol>\n"}]},"apps":[],"jobName":"paragraph_1591819974636_532865195","id":"20181126-133017_244739700","dateCreated":"2020-06-10T20:12:54+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:874"}],"name":"ScalaSpark/07-WorkingWithRDDs","id":"2FBVK71EF","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"sh:shared_process":[],"jdbc:shared_process":[],"spark2:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}